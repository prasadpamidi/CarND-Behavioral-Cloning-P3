{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Dropout, Cropping2D, Convolution2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "KERAS_CHECKPOINT_FILE_PATH = 'keras.weights.best.hdf5'\n",
    "KERAS_MODEL_WEIGHTS_FILE_PATH = 'keras.weights.h5'\n",
    "TRAIN_DATA_FOLDER = \"/data\"\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_zero_bias(data_frame):\n",
    "    \"\"\"\n",
    "    Randomly deletes zero angle steering records to reduce zero angle bias.\n",
    "    \"\"\"\n",
    "    rows_with_steering_zero = data_frame[(data_frame.steering == 0)]\n",
    "    drop_indices = np.random.choice(rows_with_steering_zero.index,\n",
    "                                    int(len(rows_with_steering_zero) * 0.7),\n",
    "                                    replace=False)\n",
    "    return data_frame.drop(drop_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load track data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(directory, correction_factor):\n",
    "    \"\"\"\n",
    "    Read the data csv file, generates image paths and measurements.\n",
    "    \"\"\"\n",
    "    csv_file_path = directory + '/driving_log.csv'\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        return []\n",
    "\n",
    "    data_frame = pd.read_csv(csv_file_path,\n",
    "                             names=['center', 'left', 'right',\n",
    "                                    'steering', 'throttle', 'brake', 'speed'])\n",
    "\n",
    "    data_frame = remove_zero_bias(data_frame)\n",
    "\n",
    "    processed_results = []\n",
    "    images_dir = directory + '/IMG/'\n",
    "    if not os.path.exists(images_dir):\n",
    "        return processed_results\n",
    "\n",
    "    for line in data_frame.itertuples():\n",
    "        if float(line.speed) < 0.1:\n",
    "            continue\n",
    "\n",
    "        steering_center = float(line.steering)\n",
    "        steering_left = steering_center+correction_factor\n",
    "        steering_right = steering_center-correction_factor\n",
    "\n",
    "        img_center_path = images_dir+line.center.split('/')[-1]\n",
    "        img_left_path = images_dir+line.left.split('/')[-1]\n",
    "        img_right_path = images_dir+line.right.split('/')[-1]\n",
    "\n",
    "        processed_results.append((img_center_path, steering_center))\n",
    "        processed_results.append((img_left_path, steering_left))\n",
    "        processed_results.append((img_right_path, steering_right))\n",
    "\n",
    "    return processed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1218422b0>,\n",
       "  <matplotlib.axis.XTick at 0x12188f198>,\n",
       "  <matplotlib.axis.XTick at 0x121bbee80>,\n",
       "  <matplotlib.axis.XTick at 0x121fe41d0>,\n",
       "  <matplotlib.axis.XTick at 0x121fe4be0>,\n",
       "  <matplotlib.axis.XTick at 0x121fe9630>,\n",
       "  <matplotlib.axis.XTick at 0x121fee080>,\n",
       "  <matplotlib.axis.XTick at 0x121fe4cf8>,\n",
       "  <matplotlib.axis.XTick at 0x115b21be0>,\n",
       "  <matplotlib.axis.XTick at 0x121bb1a58>],\n",
       " <a list of 10 Text xticklabel objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAFuCAYAAACiD0MTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e705588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "samples = process_data('data', 0.25)\n",
    "unique_rotation_angles, unique_rotation_angle_counts = np.unique([x[1] for x in samples], return_counts=True)\n",
    "\n",
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "axes.plot(unique_rotation_angles, unique_rotation_angle_counts)\n",
    "plt.xticks(list(plt.xticks()[0]) + [-0.25, 0.0, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data/Image Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Credits to Vivek Yadav.\n",
    "# Link: https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9\n",
    "def random_brightness_image(image):\n",
    "    \"\"\"\n",
    "    Returns an image with a random degree of brightness.\n",
    "    \"\"\"\n",
    "    dst = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    dst = np.array(dst, dtype=np.float64)\n",
    "    random_bright = .5+np.random.uniform()\n",
    "    dst[:, :, 2] = dst[:, :, 2]*random_bright\n",
    "    dst[:, :, 2][dst[:, :, 2] > 255] = 255\n",
    "    dst = np.array(dst, dtype=np.uint8)\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_HSV2RGB)\n",
    "    return dst\n",
    "\n",
    "# Credits to Jeremy Shannon.\n",
    "# Link: https://github.com/jeremy-shannon/CarND-Behavioral-Cloning-Project/blob/master/model.py#L110\n",
    "def random_shift_image(image):\n",
    "    '''\n",
    "    Apply warp tranform the image\n",
    "    '''\n",
    "    h, w, _ = image.shape\n",
    "    horizon = 2*h/5\n",
    "    v_shift = np.random.randint(-h/8, h/8)\n",
    "    pts1 = np.float32([[0, horizon], [w, horizon], [0, h], [w, h]])\n",
    "    pts2 = np.float32([[0, horizon+v_shift], [w, horizon+v_shift], [0, h], [w, h]])\n",
    "    return cv2.warpPerspective(image, cv2.getPerspectiveTransform(pts1, pts2),\n",
    "                               (w, h), borderMode=cv2.BORDER_REPLICATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator for train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32, validation=False):\n",
    "    \"\"\"\n",
    "    Returns a generator for the required images and augmented images from the given set of samples.\n",
    "    \"\"\"\n",
    "    num_samples = len(samples)\n",
    "\n",
    "    while 1:\n",
    "        samples = shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            augmented_images, augmented_measurements = [], []\n",
    "            output_folder = os.path.dirname(os.path.realpath(__file__))+\"/output_images/\"\n",
    "\n",
    "            for image_path, measurement in batch_samples:\n",
    "                image = cv2.imread(image_path)\n",
    "                cv2.imwrite(output_folder+\"input_\"+image_path.split(\"/\")[-1], image)\n",
    "                image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "                cv2.imwrite(output_folder+\"gaussian_\"+image_path.split(\"/\")[-1], image)\n",
    "\n",
    "                if not validation:\n",
    "                    image = random_brightness_image(image)\n",
    "                    cv2.imwrite(output_folder+\"brightness_\"+image_path.split(\"/\")[-1], image)\n",
    "                    image = random_shift_image(image)\n",
    "                    cv2.imwrite(output_folder+\"warpped_\"+image_path.split(\"/\")[-1], image)\n",
    "\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                augmented_images.append(image)\n",
    "                augmented_measurements.append(measurement)\n",
    "\n",
    "                if abs(measurement) > 0.3:\n",
    "                    image = cv2.flip(image, 1)\n",
    "                    augmented_images.append(image)\n",
    "                    augmented_measurements.append(measurement*-1.0)\n",
    "\n",
    "                x_train = np.array(augmented_images)\n",
    "                y_train = np.array(augmented_measurements)\n",
    "\n",
    "                yield shuffle(x_train, y_train)\n",
    "                x_train, y_train = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing keras layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_preprocessing_layers(model):\n",
    "    \"\"\"\n",
    "    Apply some common data preprocessing layers to the keras model.\n",
    "    \"\"\"\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160, 320, 3)))\n",
    "    model.add(Cropping2D(cropping=((70, 25), (0, 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network with LeNET Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lenet_arch_model():\n",
    "    \"\"\"\n",
    "    Returns the keras model for the LENET architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    add_preprocessing_layers(model)\n",
    "\n",
    "    model.add(Convolution2D(6, kernel_size=(5, 5), padding=\"valid\",\n",
    "                            activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(16, kernel_size=(5, 5), padding=\"valid\",\n",
    "                            activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(120, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.65))\n",
    "    model.add(Dense(84, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.65))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network with NVIDIA Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nvidia_arch_model():\n",
    "    \"\"\"\n",
    "    Returns the keras model for the popular NVIDIA architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    add_preprocessing_layers(model)\n",
    "\n",
    "    model.add(Convolution2D(24, 5, strides=(2, 2), kernel_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(36, 5, strides=(2, 2), kernel_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(48, 5, strides=(2, 2), kernel_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64, (3, 3), kernel_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64, (3, 3), kernel_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, kernel_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(50, kernel_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10, kernel_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Keras Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_model_loss(hist_object):\n",
    "    \"\"\"\n",
    "    Visualize the loss metrics for the keras model .\n",
    "    \"\"\"\n",
    "    plt.plot(hist_object.history['loss'])\n",
    "    plt.plot(hist_object.history['val_loss'])\n",
    "    plt.title('Mean Squared Error Loss')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training set', 'Validation set'], loc='upper right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When using a generator for validation data, you must specify a value for `validation_steps`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ba4eb5b2f291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m                                            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                                            callbacks=keras_model_callbacks())\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tittu/anaconda/envs/py352/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tittu/anaconda/envs/py352/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1115\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tittu/anaconda/envs/py352/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tittu/anaconda/envs/py352/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                    isinstance(validation_data, Sequence))\n\u001b[1;32m   1734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_gen\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             raise ValueError('When using a generator for validation data, '\n\u001b[0m\u001b[1;32m   1736\u001b[0m                              \u001b[0;34m'you must specify a value for '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                              '`validation_steps`.')\n",
      "\u001b[0;31mValueError\u001b[0m: When using a generator for validation data, you must specify a value for `validation_steps`."
     ]
    }
   ],
   "source": [
    "### Splitting samples and creating generators.\n",
    "data_samples = utils.process_data(os.path.dirname(os.path.realpath(__file__))+TRAIN_DATA_FOLDER, 0.25)\n",
    "train_samples, validation_samples = train_test_split(data_samples, test_size=0.2)\n",
    "\n",
    "### Create seperate generators for training and validation data\n",
    "train_generator = utils.generator(train_samples, batch_size=BATCH_SIZE)\n",
    "validation_generator = utils.generator(validation_samples, batch_size=BATCH_SIZE, validation=True)\n",
    "\n",
    "### Create a keras model\n",
    "keras_model = nvidia_arch_model()\n",
    "\n",
    "\n",
    "### Load any previous saved model weights, if exists\n",
    "if os.path.exists(KERAS_MODEL_WEIGHTS_FILE_PATH):\n",
    "    keras_model.load_weights(KERAS_MODEL_WEIGHTS_FILE_PATH)\n",
    "else:\n",
    "    print(\"No prior saved model weights exist\")\n",
    "\n",
    "### Compile and train the model using the generator function\n",
    "keras_model.compile(loss='mse', optimizer=Adam(lr=1e-5), metrics=['accuracy'])\n",
    "\n",
    "history_object = keras_model.fit_generator(train_generator,\n",
    "                                           steps_per_epoch=int(np.floor((len(train_samples))\n",
    "                                                                        /BATCH_SIZE)*BATCH_SIZE),\n",
    "                                           validation_data=validation_generator,\n",
    "                                           validation_steps=int(np.floor((len(validation_samples))\n",
    "                                                                         /BATCH_SIZE)*BATCH_SIZE),\n",
    "                                           epochs=5,\n",
    "                                           verbose=1,\n",
    "                                           callbacks=[ModelCheckpoint(KERAS_CHECKPOINT_FILE_PATH,\n",
    "                                                                      verbose=1,\n",
    "                                                                      save_best_only=True)])\n",
    "\n",
    "keras_model.save_weights(KERAS_MODEL_WEIGHTS_FILE_PATH)\n",
    "keras_model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate visualization of the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(keras_model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the model loss over training and validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize_model_loss(history_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
